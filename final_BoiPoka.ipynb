{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"iyIJ6u1h6-BE","executionInfo":{"status":"ok","timestamp":1687516763763,"user_tz":-360,"elapsed":18809,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8697340-7821-4d3e-b43b-94dcf6cf5cad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# All packages\n","\n","from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n","import pandas as pd\n","import numpy as np\n","\n","#mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMZsBPa01kJu","executionInfo":{"status":"ok","timestamp":1687516766016,"user_tz":-360,"elapsed":2257,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"}},"outputId":"9add1305-7052-4a55-d2f9-ff3737d93e0c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":4393,"status":"ok","timestamp":1687516777889,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"},"user_tz":-360},"id":"xmyLrwdZ7TEj","outputId":"ff166402-9139-463d-9b69-57617473d444"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-c0b5872f75bb>:9: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n","  dataset[['urlID', 'Title', 'Author', 'Publisher', 'Price', 'DiscountedPrice', 'Discount', 'Category', 'ISBN', 'Edition', 'Pages', 'Country', 'Language', 'Ratings', 'RatingsNum', 'Reviews']] = dataset['Column'].str.split('|', 16, expand=True)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_00099d45-4cc2-4328-843b-40c4734e2af5\", \"output.csv\", 25851820)"]},"metadata":{}}],"source":["## Dataset ##\n","\n","# loading dataset\n","dataset = pd.read_csv('/content/drive/MyDrive/AI Project/Bangla books details data/books.csv', on_bad_lines='skip')\n","\n","dataset = dataset.rename(columns={\"urlID|Title|Author|Publisher|Price|DiscountedPrice|Discount|Category|ISBN|Edition|Pages|Country|Language|Ratings|RatingsNum|Reviews\": \"Column\"})\n","\n","# splitting into multiple column\n","dataset[['urlID', 'Title', 'Author', 'Publisher', 'Price', 'DiscountedPrice', 'Discount', 'Category', 'ISBN', 'Edition', 'Pages', 'Country', 'Language', 'Ratings', 'RatingsNum', 'Reviews']] = dataset['Column'].str.split('|', 16, expand=True)\n","\n","# removing duplicate occurance of same book\n","dataset = dataset.drop_duplicates(subset=['Title', 'Author'])\n","\n","# removing information about books which are not in Bangla\n","dataset = dataset[dataset['Language'] == 'Bangla']\n","\n","# removing unnecessary columns\n","dataset = dataset.drop(columns=['Column', 'ISBN', 'Edition', 'Language', 'urlID', 'DiscountedPrice', 'Discount', 'Reviews'])\n","\n","# dropping the rows having null values\n","dataset = dataset.dropna()\n","\n","\n","\n","# # making numeric\n","dataset['Ratings'] = pd.to_numeric(dataset['Ratings'], errors='coerce')\n","dataset['RatingsNum'] = pd.to_numeric(dataset['RatingsNum'], errors='coerce')\n","dataset['Price'] = pd.to_numeric(dataset['Price'], errors='coerce')\n","dataset['Pages'] = pd.to_numeric(dataset['Pages'], errors='coerce')\n","dataset['RatingsNum'] = dataset['RatingsNum'].multiply(10)\n","\n","## Remove outliers\n","dataset = dataset[(dataset['Pages'] >= 0) & (dataset['Pages'] <= 20000)]\n","dataset = dataset[(dataset['Price'] >= 0) & (dataset['Price'] <= 50000)]\n","\n","## Handeling Missing values\n","dataset['Price'] = dataset['Price'].replace([np.inf, -np.inf, np.nan], 0)\n","priceSum = dataset['Price'].sum()\n","meanPrice = priceSum / dataset[dataset['Price'] != 0].shape[0]\n","meanPrice = meanPrice.astype(int)\n","dataset.loc[dataset['Price'] == 0, 'Price'] = meanPrice\n","\n","dataset['Pages'] = dataset['Pages'].replace([np.inf, -np.inf, np.nan], 0)\n","pagesSum = dataset['Pages'].sum()\n","meanPages = pagesSum / dataset[dataset['Pages'] != 0].shape[0]\n","meanPages = meanPages.astype(int)\n","dataset.loc[dataset['Pages'] == 0, 'Pages'] = meanPages\n","\n","dataset['Ratings'] = dataset['Ratings'].replace([np.inf, -np.inf, np.nan], 0)\n","RatingsSum = dataset['Ratings'].sum()\n","meanRatings = RatingsSum / dataset[dataset['Ratings'] != 0].shape[0]\n","meanRatings = meanRatings.round(1).astype(float)\n","dataset.loc[dataset['Ratings'] == 0, 'Ratings'] = meanRatings\n","\n","dataset['RatingsNum'] = dataset['RatingsNum'].replace([np.inf, -np.inf, np.nan], 0)\n","dataset['RatingsNum'] = dataset['RatingsNum'].astype(int)\n","RatingsNumSum = dataset['RatingsNum'].sum()\n","meanRatingsNum = RatingsNumSum / dataset[dataset['RatingsNum'] != 0].shape[0]\n","meanRatingsNum = meanRatingsNum.astype(int)\n","dataset.loc[dataset['RatingsNum'] == 0, 'RatingsNum'] = meanRatingsNum\n","\n","# # df_sorted = dataset.sort_values('RatingsNum')\n","# # df_sorted\n","\n","from google.colab import files\n","dataset.to_csv('output.csv', encoding = 'utf-8-sig')\n","files.download('output.csv')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":696},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687516789793,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"},"user_tz":-360},"id":"6tkCT6vbRqZ_","outputId":"aef6be07-9c5a-4d48-e820-9c18428639d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               Title             Author          Publisher  \\\n","0                   সুশাসনের সন্ধানে        আতিউর রহমান         অন্যপ্রকাশ   \n","1                        শেষের কবিতা  রবীন্দ্রনাথ ঠাকুর   বিশ্বসাহিত্য ভবন   \n","2                           নৌকাডুবি  রবীন্দ্রনাথ ঠাকুর   বিশ্বসাহিত্য ভবন   \n","3                               গোরা  রবীন্দ্রনাথ ঠাকুর   বিশ্বসাহিত্য ভবন   \n","4                         চোখের বালি  রবীন্দ্রনাথ ঠাকুর   বিশ্বসাহিত্য ভবন   \n","...                              ...                ...                ...   \n","142344  জীবনানন্দ দাশের শ্রেষ্ঠ গল্প      মামুনুর রহমান             সমাচার   \n","142345                        তনু-মন           ইব্রাহিম          তুষারধারা   \n","142395                       ও নদীরে        আসাদ চৌধুরী  প্রজ্জ্বলন প্রকাশ   \n","142396                         স্রোত      মামুনুল ইসলাম  প্রজ্জ্বলন প্রকাশ   \n","142397                  তুমিও কাঁদবে      হারুন-অর-রশিদ  প্রজ্জ্বলন প্রকাশ   \n","\n","        Price          Category  Pages     Country  Ratings  RatingsNum  \n","0         276  প্রসঙ্গ বাংলাদেশ    215  Bangladesh      5.0          30  \n","1          90    চিরায়ত উপন্যাস     78  Bangladesh      4.6         100  \n","2         158    চিরায়ত উপন্যাস    156  Bangladesh      5.0          40  \n","3         255    চিরায়ত উপন্যাস    239  Bangladesh      5.0          30  \n","4         158    চিরায়ত উপন্যাস    156  Bangladesh      5.0          40  \n","...       ...               ...    ...         ...      ...         ...  \n","142344    350       বইমেলা ২০১৮    352  Bangladesh      4.9          20  \n","142345    120       বইমেলা ২০১৮    177  Bangladesh      4.9          20  \n","142395    135       বইমেলা ২০১৮    177  Bangladesh      4.9          20  \n","142396    180       বইমেলা ২০১৮    177  Bangladesh      4.9          20  \n","142397    130       বইমেলা ২০১৮    177  Bangladesh      4.9          20  \n","\n","[102327 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-f1fd3f7a-e077-4c3d-97fd-df65a92a3b91\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Author</th>\n","      <th>Publisher</th>\n","      <th>Price</th>\n","      <th>Category</th>\n","      <th>Pages</th>\n","      <th>Country</th>\n","      <th>Ratings</th>\n","      <th>RatingsNum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>সুশাসনের সন্ধানে</td>\n","      <td>আতিউর রহমান</td>\n","      <td>অন্যপ্রকাশ</td>\n","      <td>276</td>\n","      <td>প্রসঙ্গ বাংলাদেশ</td>\n","      <td>215</td>\n","      <td>Bangladesh</td>\n","      <td>5.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>শেষের কবিতা</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>90</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>78</td>\n","      <td>Bangladesh</td>\n","      <td>4.6</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>নৌকাডুবি</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>158</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>156</td>\n","      <td>Bangladesh</td>\n","      <td>5.0</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>গোরা</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>255</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>239</td>\n","      <td>Bangladesh</td>\n","      <td>5.0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>চোখের বালি</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>158</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>156</td>\n","      <td>Bangladesh</td>\n","      <td>5.0</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142344</th>\n","      <td>জীবনানন্দ দাশের শ্রেষ্ঠ গল্প</td>\n","      <td>মামুনুর রহমান</td>\n","      <td>সমাচার</td>\n","      <td>350</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>352</td>\n","      <td>Bangladesh</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>142345</th>\n","      <td>তনু-মন</td>\n","      <td>ইব্রাহিম</td>\n","      <td>তুষারধারা</td>\n","      <td>120</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>142395</th>\n","      <td>ও নদীরে</td>\n","      <td>আসাদ চৌধুরী</td>\n","      <td>প্রজ্জ্বলন প্রকাশ</td>\n","      <td>135</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>142396</th>\n","      <td>স্রোত</td>\n","      <td>মামুনুল ইসলাম</td>\n","      <td>প্রজ্জ্বলন প্রকাশ</td>\n","      <td>180</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>142397</th>\n","      <td>তুমিও কাঁদবে</td>\n","      <td>হারুন-অর-রশিদ</td>\n","      <td>প্রজ্জ্বলন প্রকাশ</td>\n","      <td>130</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>102327 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1fd3f7a-e077-4c3d-97fd-df65a92a3b91')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f1fd3f7a-e077-4c3d-97fd-df65a92a3b91 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f1fd3f7a-e077-4c3d-97fd-df65a92a3b91');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":696},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1687516794292,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"},"user_tz":-360},"id":"WIRd39zjulV-","outputId":"fbe544b9-6782-4f4c-d54f-ae83b4e08d10"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               Title             Author          Category  \\\n","0                   সুশাসনের সন্ধানে        আতিউর রহমান  প্রসঙ্গ বাংলাদেশ   \n","1                        শেষের কবিতা  রবীন্দ্রনাথ ঠাকুর    চিরায়ত উপন্যাস   \n","2                           নৌকাডুবি  রবীন্দ্রনাথ ঠাকুর    চিরায়ত উপন্যাস   \n","3                               গোরা  রবীন্দ্রনাথ ঠাকুর    চিরায়ত উপন্যাস   \n","4                         চোখের বালি  রবীন্দ্রনাথ ঠাকুর    চিরায়ত উপন্যাস   \n","...                              ...                ...               ...   \n","142344  জীবনানন্দ দাশের শ্রেষ্ঠ গল্প      মামুনুর রহমান       বইমেলা ২০১৮   \n","142345                        তনু-মন           ইব্রাহিম       বইমেলা ২০১৮   \n","142395                       ও নদীরে        আসাদ চৌধুরী       বইমেলা ২০১৮   \n","142396                         স্রোত      মামুনুল ইসলাম       বইমেলা ২০১৮   \n","142397                  তুমিও কাঁদবে      হারুন-অর-রশিদ       বইমেলা ২০১৮   \n","\n","        Ratings  RatingsNum  Price          Publisher  Pages     Country  \n","0           5.0          30    276         অন্যপ্রকাশ    215  Bangladesh  \n","1           4.6         100     90   বিশ্বসাহিত্য ভবন     78  Bangladesh  \n","2           5.0          40    158   বিশ্বসাহিত্য ভবন    156  Bangladesh  \n","3           5.0          30    255   বিশ্বসাহিত্য ভবন    239  Bangladesh  \n","4           5.0          40    158   বিশ্বসাহিত্য ভবন    156  Bangladesh  \n","...         ...         ...    ...                ...    ...         ...  \n","142344      4.9          20    350             সমাচার    352  Bangladesh  \n","142345      4.9          20    120          তুষারধারা    177  Bangladesh  \n","142395      4.9          20    135  প্রজ্জ্বলন প্রকাশ    177  Bangladesh  \n","142396      4.9          20    180  প্রজ্জ্বলন প্রকাশ    177  Bangladesh  \n","142397      4.9          20    130  প্রজ্জ্বলন প্রকাশ    177  Bangladesh  \n","\n","[102327 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-8df5855d-0348-443b-8a48-97570cc5252b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Author</th>\n","      <th>Category</th>\n","      <th>Ratings</th>\n","      <th>RatingsNum</th>\n","      <th>Price</th>\n","      <th>Publisher</th>\n","      <th>Pages</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>সুশাসনের সন্ধানে</td>\n","      <td>আতিউর রহমান</td>\n","      <td>প্রসঙ্গ বাংলাদেশ</td>\n","      <td>5.0</td>\n","      <td>30</td>\n","      <td>276</td>\n","      <td>অন্যপ্রকাশ</td>\n","      <td>215</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>শেষের কবিতা</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>4.6</td>\n","      <td>100</td>\n","      <td>90</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>78</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>নৌকাডুবি</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>5.0</td>\n","      <td>40</td>\n","      <td>158</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>156</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>গোরা</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>5.0</td>\n","      <td>30</td>\n","      <td>255</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>239</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>চোখের বালি</td>\n","      <td>রবীন্দ্রনাথ ঠাকুর</td>\n","      <td>চিরায়ত উপন্যাস</td>\n","      <td>5.0</td>\n","      <td>40</td>\n","      <td>158</td>\n","      <td>বিশ্বসাহিত্য ভবন</td>\n","      <td>156</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>142344</th>\n","      <td>জীবনানন্দ দাশের শ্রেষ্ঠ গল্প</td>\n","      <td>মামুনুর রহমান</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","      <td>350</td>\n","      <td>সমাচার</td>\n","      <td>352</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>142345</th>\n","      <td>তনু-মন</td>\n","      <td>ইব্রাহিম</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","      <td>120</td>\n","      <td>তুষারধারা</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>142395</th>\n","      <td>ও নদীরে</td>\n","      <td>আসাদ চৌধুরী</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","      <td>135</td>\n","      <td>প্রজ্জ্বলন প্রকাশ</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>142396</th>\n","      <td>স্রোত</td>\n","      <td>মামুনুল ইসলাম</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","      <td>180</td>\n","      <td>প্রজ্জ্বলন প্রকাশ</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","    <tr>\n","      <th>142397</th>\n","      <td>তুমিও কাঁদবে</td>\n","      <td>হারুন-অর-রশিদ</td>\n","      <td>বইমেলা ২০১৮</td>\n","      <td>4.9</td>\n","      <td>20</td>\n","      <td>130</td>\n","      <td>প্রজ্জ্বলন প্রকাশ</td>\n","      <td>177</td>\n","      <td>Bangladesh</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>102327 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8df5855d-0348-443b-8a48-97570cc5252b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8df5855d-0348-443b-8a48-97570cc5252b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8df5855d-0348-443b-8a48-97570cc5252b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["feature_weights = {\n","    'Title':0.9,\n","    'Author': 0.8,\n","    'Category': 0.75,\n","    'Ratings': 0.65,\n","    'RatingsNum': 0.65,\n","    'Price': 0.6,\n","    'Publisher': 0.5,\n","    'Pages': 0.4,\n","    'Country': 0.2\n","}\n","\n","sorted_features = sorted(feature_weights, key=feature_weights.get, reverse=True)\n","\n","selected_columns = sorted_features + [col for col in dataset.columns if col not in sorted_features]\n","processed_dataset = dataset[selected_columns]\n","\n","processed_dataset\n"]},{"cell_type":"code","source":["import nltk\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.tokenize import word_tokenize\n","# Download the 'punkt' resource\n","nltk.download('punkt')\n","\n","import re\n","import string\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sZo7cfPiGxq","executionInfo":{"status":"ok","timestamp":1687516800167,"user_tz":-360,"elapsed":2105,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"}},"outputId":"36f7d2c8-a6ce-4794-cf9a-3b42ed401e3f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","source":["**WhiteSpace Removal**"],"metadata":{"id":"0VO_LMrr1NjT"}},{"cell_type":"code","source":["! pip install bnlp_toolkit\n","! pip install banglanltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXaprcHV90mE","executionInfo":{"status":"ok","timestamp":1687518935658,"user_tz":-360,"elapsed":9538,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"}},"outputId":"12579175-5034-415a-eba9-d406c6b7c7bf"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bnlp_toolkit\n","  Downloading bnlp_toolkit-3.3.1-py3-none-any.whl (22 kB)\n","Collecting sentencepiece (from bnlp_toolkit)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.10.1)\n","Collecting sklearn-crfsuite (from bnlp_toolkit)\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.65.0)\n","Collecting ftfy (from bnlp_toolkit)\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emoji==1.7.0 (from bnlp_toolkit)\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp_toolkit) (0.2.6)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.3.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2022.10.31)\n","Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->bnlp_toolkit)\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.10)\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=fa08b564242648dbf7289712e43a2eb869dcd6c6ead2b6e42658ca655e2a383b\n","  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n","Successfully built emoji\n","Installing collected packages: sentencepiece, python-crfsuite, emoji, sklearn-crfsuite, ftfy, bnlp_toolkit\n","Successfully installed bnlp_toolkit-3.3.1 emoji-1.7.0 ftfy-6.1.1 python-crfsuite-0.9.9 sentencepiece-0.1.99 sklearn-crfsuite-0.3.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting banglanltk\n","  Downloading banglanltk-0.0.4-py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: banglanltk\n","Successfully installed banglanltk-0.0.4\n"]}]},{"cell_type":"code","source":["processed_dataset['Title'].apply(lambda x:[i.replace(r\"\\s+\",\"\")for i in x])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6e440JVqAVF1","executionInfo":{"status":"ok","timestamp":1687519695106,"user_tz":-360,"elapsed":848,"user":{"displayName":"Enan Abdullah Khan","userId":"15870003903938726417"}},"outputId":"20136f35-350b-4470-861b-caf4fc751eac"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          [স, ু, শ, া, স, ন, ে, র,  , স, ন, ্, ধ, া, ন, ে]\n","1                         [শ, ে, ষ, ে, র,  , ক, ব, ি, ত, া]\n","2                                  [ন, ৌ, ক, া, ড, ু, ব, ি]\n","3                                              [গ, ো, র, া]\n","4                            [চ, ো, খ, ে, র,  , ব, া, ল, ি]\n","                                ...                        \n","142344    [জ, ী, ব, ন, া, ন, ন, ্, দ,  , দ, া, শ, ে, র, ...\n","142345                                   [ত, ন, ু, -, ম, ন]\n","142395                                [ও,  , ন, দ, ী, র, ে]\n","142396                                      [স, ্, র, ো, ত]\n","142397                 [ত, ু, ম, ি, ও,  , ক, া, ঁ, দ, ব, ে]\n","Name: Title, Length: 102327, dtype: object"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["###tokenization + TF-IDF matrix#####\n","##matrix e shob value zero ashe :( ####\n","\n","\n","def preprocess_bangla_text(text):\n","    # Remove special characters and symbols specific to Bangla language\n","    text = re.sub(r'[^\\w\\sঀ-৾]', '', text)\n","\n","    # Remove leading and trailing whitespace\n","    text = text.strip()\n","\n","    return text\n","\n","# Apply preprocessing function to the columns before tokenization\n","dataset['Title'] = dataset['Title'].apply(preprocess_bangla_text)\n","dataset['Author'] = dataset['Author'].apply(preprocess_bangla_text)\n","dataset['Category'] = dataset['Category'].apply(preprocess_bangla_text)\n","dataset['Publisher'] = dataset['Publisher'].apply(preprocess_bangla_text)\n","# # Tokenize the Bangla text columns using nltk\n","dataset['Tokenized_Title'] = dataset['Title'].apply(lambda x: word_tokenize(x))\n","dataset['Tokenized_Author'] = dataset['Author'].apply(lambda x: word_tokenize(x))\n","dataset['Tokenized_Category'] = dataset['Category'].apply(lambda x: word_tokenize(x))\n","dataset['Tokenized_Publisher'] = dataset['Publisher'].apply(lambda x: word_tokenize(x))\n","# # Add more columns as needed\n","# # Combine the tokenized text columns into a single column\n","dataset['Tokenized_Text'] = dataset['Tokenized_Title'] + dataset['Tokenized_Author']+ dataset['Tokenized_Category']+ dataset['Tokenized_Publisher']\n","# Modify the concatenation as per your column requirements\n","\n","# # Convert the tokenized text into a string representation\n","dataset['Tokenized_Text'] = dataset['Tokenized_Text'].apply(lambda x: ' '.join(x))\n","\n","# # Apply TF-IDF on the tokenized text\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(dataset['Tokenized_Text'])\n","\n","# # Convert the TF-IDF matrix to a DataFrame\n","tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n","\n","# # Display the TF-IDF matrix\n","print(tfidf_df)\n"],"metadata":{"id":"U9j5H1d1jSJ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686988397484,"user_tz":-360,"elapsed":44560,"user":{"displayName":"25 Maliha Zerin","userId":"09428742832350796406"}},"outputId":"aad442cd-562f-4a53-df39-0a307f8db861"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["         10   12   13   15   16   18  1857   19  1947খ  19702010  ...  ৯৪৬৪  \\\n","0       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","1       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","2       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","3       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","4       0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","...     ...  ...  ...  ...  ...  ...   ...  ...    ...       ...  ...   ...   \n","102322  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","102323  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","102324  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","102325  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","102326  0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0    0.0       0.0  ...   0.0   \n","\n","         ৯৫  ৯৫৯৬   ৯৬   ৯৭  ৯৭৯৮   ৯৮   ৯৯  ৯৯৩  ৯৯৯  \n","0       0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","1       0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","2       0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","3       0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","4       0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","...     ...   ...  ...  ...   ...  ...  ...  ...  ...  \n","102322  0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","102323  0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","102324  0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","102325  0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","102326  0.0   0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n","\n","[102327 rows x 9806 columns]\n"]}]},{"cell_type":"code","source":["#####tokenization + count vectorization######\n","####tf-idf kore shob zero ashe tai, eti method try kora. ekhanew zero ashe :(( #####\n","\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","def preprocess_bangla_text(text):\n","    # Remove special characters and symbols specific to Bangla language\n","    text = re.sub(r'[^\\w\\sঀ-৾]', '', text)\n","\n","    # Remove leading and trailing whitespace\n","    text = text.strip()\n","\n","    return text\n","\n","# Apply preprocessing function to the columns before tokenization\n","dataset['Title'] = dataset['Title'].apply(preprocess_bangla_text)\n","dataset['Author'] = dataset['Author'].apply(preprocess_bangla_text)\n","dataset['Category'] = dataset['Category'].apply(preprocess_bangla_text)\n","dataset['Publisher'] = dataset['Publisher'].apply(preprocess_bangla_text)\n","\n","# Tokenize the Bangla text columns using nltk\n","dataset['Tokenized_Title'] = dataset['Title'].apply(lambda x: word_tokenize(x))\n","dataset['Tokenized_Author'] = dataset['Author'].apply(lambda x: word_tokenize(x))\n","dataset['Tokenized_Category'] = dataset['Category'].apply(lambda x: word_tokenize(x))\n","dataset['Tokenized_Publisher'] = dataset['Publisher'].apply(lambda x: word_tokenize(x))\n","# Add more columns as needed\n","\n","# Combine the tokenized text columns into a single column\n","dataset['Tokenized_Text'] = dataset['Tokenized_Title'] + dataset['Tokenized_Author'] + dataset['Tokenized_Category'] + dataset['Tokenized_Publisher']\n","# Modify the concatenation as per your column requirements\n","\n","# Convert the tokenized text into a string representation\n","dataset['Tokenized_Text'] = dataset['Tokenized_Text'].apply(lambda x: ' '.join(x))\n","\n","# Apply count vectorization on the tokenized text\n","count_vectorizer = CountVectorizer()\n","count_matrix = count_vectorizer.fit_transform(dataset['Tokenized_Text'])\n","\n","# Convert the count matrix to a DataFrame\n","count_df = pd.DataFrame(count_matrix.toarray(), columns=count_vectorizer.get_feature_names_out())\n","\n","# Display the count matrix\n","print(count_df)"],"metadata":{"id":"yhWCuof9jTLb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686988772864,"user_tz":-360,"elapsed":42200,"user":{"displayName":"25 Maliha Zerin","userId":"09428742832350796406"}},"outputId":"d610718d-1388-4b32-8caf-d0629aba38d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        10  12  13  15  16  18  1857  19  1947খ  19702010  ...  ৯৪৬৪  ৯৫  \\\n","0        0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","1        0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","2        0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","3        0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","4        0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","...     ..  ..  ..  ..  ..  ..   ...  ..    ...       ...  ...   ...  ..   \n","102322   0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","102323   0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","102324   0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","102325   0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","102326   0   0   0   0   0   0     0   0      0         0  ...     0   0   \n","\n","        ৯৫৯৬  ৯৬  ৯৭  ৯৭৯৮  ৯৮  ৯৯  ৯৯৩  ৯৯৯  \n","0          0   0   0     0   0   0    0    0  \n","1          0   0   0     0   0   0    0    0  \n","2          0   0   0     0   0   0    0    0  \n","3          0   0   0     0   0   0    0    0  \n","4          0   0   0     0   0   0    0    0  \n","...      ...  ..  ..   ...  ..  ..  ...  ...  \n","102322     0   0   0     0   0   0    0    0  \n","102323     0   0   0     0   0   0    0    0  \n","102324     0   0   0     0   0   0    0    0  \n","102325     0   0   0     0   0   0    0    0  \n","102326     0   0   0     0   0   0    0    0  \n","\n","[102327 rows x 9806 columns]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Calculate cosine similarity\n","cosine_sim_matrix = cosine_similarity(count_matrix, count_matrix)\n","\n","# Create a DataFrame from the cosine similarity matrix\n","cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=dataset.index, columns=dataset.index)\n","\n","# Display the cosine similarity matrix\n","print(cosine_sim_df)\n"],"metadata":{"id":"UjWS2sCCjVPQ","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1687450870920,"user_tz":-360,"elapsed":40,"user":{"displayName":"25 Maliha Zerin","userId":"09428742832350796406"}},"outputId":"595c0029-6524-4bc5-b12e-8a7811c1de6c"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-bb97316903c6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calculate cosine similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcosine_sim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a DataFrame from the cosine similarity matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'count_matrix' is not defined"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}